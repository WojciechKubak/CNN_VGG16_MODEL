{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LE5y9ASEctNR"
      },
      "source": [
        "### **Download dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ASYr19YScHKN"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wYXtk8rUpZNx"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bh01J2dgcPrL"
      },
      "outputs": [],
      "source": [
        "!kaggle datasets download -d tawsifurrahman/covid19-radiography-database"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWXA4OA9duJY"
      },
      "source": [
        "### **Extract dataset files**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "06EjQIr6cirS"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "path = '/content/covid19-radiography-database.zip'\n",
        "with zipfile.ZipFile(path, 'r') as zip:\n",
        "  zip.extractall()\n",
        "os.remove(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "QRI93rcmdbpx"
      },
      "outputs": [],
      "source": [
        "filenames = list()\n",
        "dataset_path = '/content/COVID-19_Radiography_Dataset'\n",
        "for dir, _, filename in os.walk(dataset_path):\n",
        "  if 'images' in dir:\n",
        "    filenames.append(filename)\n",
        "filenames = [item for sublist in filenames for item in sublist]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "UeIInybCfQ41"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "all_image_paths = {os.path.basename(x): x for x in glob.glob(os.path.join(dataset_path, '*/', 'images', '*.png'))}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "9aZ2-i_WgHQI"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame(data = {'image': filenames})\n",
        "df['path'] = df.image.map(all_image_paths)\n",
        "df['label'] = df.image.apply(lambda x: x.split('-')[0])\n",
        "df.drop(columns = 'image', inplace = True)\n",
        "df = df.sample(frac = 1)\n",
        "df.reset_index(drop = True, inplace = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCYuPPf3iTLQ"
      },
      "source": [
        "### **Dataset analysis**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ci3W6LVKiW2E"
      },
      "outputs": [],
      "source": [
        "import plotly.express as px\n",
        "fig = px.bar(data_frame = df,\n",
        "             x = df.label.value_counts().index,\n",
        "             y = df.label.value_counts().values,\n",
        "             text_auto = True)\n",
        "\n",
        "fig.update_layout(title = 'Class distribution', \n",
        "                  xaxis_title = \"class name\", \n",
        "                  yaxis_title = \"number of occurrences\", \n",
        "                  legend_title = \"Legend Title\")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Az1IbNuEkbrY"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "def read_image(path, IMG_SIZE = (256, 256)):\n",
        "  image = cv2.imread(path)\n",
        "  image = cv2.resize(image, IMG_SIZE)\n",
        "  return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zf01azQ2inwG"
      },
      "outputs": [],
      "source": [
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go\n",
        "import random\n",
        "fig = make_subplots(rows = 2,\n",
        "                    cols = 4,\n",
        "                    subplot_titles = df.label.unique(), \n",
        "                    vertical_spacing = 0.1)\n",
        "\n",
        "for index, label in enumerate(df.label.unique()):\n",
        "  label_mask = df.label == label\n",
        "  \n",
        "  sample = df.loc[label_mask, 'path'].sample(1)\n",
        "  image = read_image(sample.values[0])\n",
        "  fig.add_trace(go.Image(z = image), row = 1, col = index + 1)\n",
        "\n",
        "  sample = df.loc[label_mask, 'path'].sample(1)\n",
        "  image = read_image(sample.values[0])\n",
        "  fig.add_trace(go.Image(z = image), row = 2, col = index + 1)\n",
        "\n",
        "fig.update_xaxes(visible = False)\n",
        "fig.update_yaxes(visible = False)\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIijYE9bnhSQ"
      },
      "source": [
        "### **Data preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "gFJCJcJRLzQ4"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "labels = encoder.fit_transform(df.values[:,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "KLes6o4eL7i5"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils import class_weight\n",
        "import numpy as np\n",
        "class_weights = class_weight.compute_class_weight(class_weight = 'balanced',\n",
        "                                                  classes = np.unique(labels),\n",
        "                                                  y = labels)\n",
        "weights_dict = {np.unique(labels)[i]: class_weights[i] for i in range(len(class_weights))}\n",
        "weights = np.asarray(list(map(weights_dict.get, labels)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "NMWo98tlL2Jv"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "hot_encoder = OneHotEncoder()\n",
        "labels = hot_encoder.fit_transform(labels.reshape(-1, 1))\n",
        "labels = labels.toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "q5QSbeu2vMHj"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "path_tensor = tf.convert_to_tensor(df.values[:,0])\n",
        "label_tensor = tf.convert_to_tensor(labels)\n",
        "weight_tensor = tf.convert_to_tensor(weights)\n",
        "dataset = tf.data.Dataset.from_tensor_slices(tensors = (path_tensor, label_tensor, weight_tensor))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "RqkC1ghRRZkh"
      },
      "outputs": [],
      "source": [
        "def load_images(path, label, weight, IMG_SIZE = (224, 224)):\n",
        "  image = tf.io.read_file(path)\n",
        "  image = tf.image.decode_image(image, channels = 3,\n",
        "                                expand_animations = False)\n",
        "  image = tf.image.resize(image, IMG_SIZE)\n",
        "  image = tf.cast(image, dtype = tf.float32)\n",
        "  label = tf.cast(label, dtype = tf.float16)\n",
        "  weight = tf.cast(weight, dtype = tf.float16)\n",
        "  return image, label, weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "nl5E24Y4p0_x"
      },
      "outputs": [],
      "source": [
        "dataset = dataset.map(load_images, num_parallel_calls=tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "R6xIC_KIvk-9"
      },
      "outputs": [],
      "source": [
        "DATASET_SIZE = len(dataset)\n",
        "\n",
        "train_size = int(0.7 * DATASET_SIZE)\n",
        "val_size = int(0.15 * DATASET_SIZE)\n",
        "test_size = int(0.15 * DATASET_SIZE)\n",
        "\n",
        "train_dataset = dataset.take(train_size)\n",
        "test_dataset = dataset.skip(train_size)\n",
        "val_dataset = test_dataset.skip(val_size)\n",
        "test_dataset = test_dataset.take(test_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "2xw6KWCnZcxj"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "val_dataset = val_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-cv4cxRv6oo"
      },
      "source": [
        "### **Building and training model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "iFiWfp1CvzBg"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Input, Flatten, Dense, Activation, BatchNormalization, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "NUM_CLASSES = 4\n",
        "IMG_SIZE = (224, 224, 3)\n",
        "\n",
        "def create_model(classes, shape, INIT_LR = 3e-4):\n",
        "  feature_extractor = VGG16(include_top = False, weights = 'imagenet')\n",
        "  feature_extractor.trainable = False\n",
        "\n",
        "  inputs = Input(shape = shape, dtype = tf.float16, name = 'input_layer')\n",
        "  extractor = feature_extractor(inputs)\n",
        "\n",
        "  flatten = Flatten(name = 'flatten_layer')(extractor)\n",
        "\n",
        "  classifier = Dense(2048)(flatten)\n",
        "  classifier = Activation('relu', dtype = tf.float32)(classifier)\n",
        "  classifier = Dropout(0.5)(classifier)\n",
        "  classifier = BatchNormalization()(classifier)\n",
        "\n",
        "  classifier = Dense(classes)(classifier)\n",
        "  outputs = Activation(activation = 'softmax', \n",
        "                       dtype = tf.float32, \n",
        "                       name = 'softmax_output')(classifier)\n",
        "\n",
        "  model = Model(inputs = inputs, outputs = outputs)\n",
        "\n",
        "  model.compile(optimizer = Adam(learning_rate = INIT_LR),\n",
        "                loss = 'categorical_crossentropy', \n",
        "                metrics = 'accuracy')\n",
        "  \n",
        "  return model \n",
        "\n",
        "model = create_model(NUM_CLASSES, IMG_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "io3J7VfCu2iY"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stopping = EarlyStopping(monitor = 'val_accuracy',\n",
        "                              patience = 3,\n",
        "                              verbose = 0,\n",
        "                              restore_best_weights = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "f5og7SrIu-Ch"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "EPOCHS = 100\n",
        "scheduler = lambda x: 3e-4 * 0.95 ** (x + EPOCHS)\n",
        "lr_scheduler = LearningRateScheduler(schedule =scheduler, verbose = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "r5YRfsjDvFKU"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "path = \"CHECKPOINTS/cp.ckpt\" \n",
        "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath = path, \n",
        "                                                     montior = \"val_accuracy\",\n",
        "                                                     save_best_only = True,\n",
        "                                                     save_weights_only = True,\n",
        "                                                     verbose = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "urd0B36AyOaJ"
      },
      "outputs": [],
      "source": [
        "history = model.fit(x=train_dataset,\n",
        "                    epochs=EPOCHS,\n",
        "                    validation_data=val_dataset, \n",
        "                    batch_size = BATCH_SIZE,\n",
        "                    verbose=2,\n",
        "                    callbacks=[early_stopping, lr_scheduler, model_checkpoint])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ah3fR7grCpJH"
      },
      "outputs": [],
      "source": [
        "df_history = pd.DataFrame(data = history.history)\n",
        "subplot_titles = ['training', 'validation']\n",
        "xaxis_title, yaxis_title = 'epoch', 'loss & accuracy'\n",
        "\n",
        "fig = make_subplots(rows = 1, cols = 2, subplot_titles = subplot_titles)\n",
        "\n",
        "fig.add_trace(go.Line(x = df_history.index, y = df_history.loss, name = 'loss'), row = 1, col = 1)\n",
        "fig.add_trace(go.Line(x = df_history.index, y = df_history.accuracy, name = 'accuracy'), row = 1, col = 1)\n",
        "fig.update_xaxes(title_text=xaxis_title, row = 1, col = 1)\n",
        "fig.update_yaxes(title_text=yaxis_title, row = 1, col = 1)\n",
        "\n",
        "fig.add_trace(go.Line(x = df_history.index, y = df_history.val_loss, name = 'val_loss'), row = 1, col = 2)\n",
        "fig.add_trace(go.Line(x = df_history.index, y = df_history.val_accuracy, name = 'val_accuracy'), row = 1, col = 2)\n",
        "fig.update_xaxes(title_text=xaxis_title, row = 1, col = 2)\n",
        "fig.update_yaxes(title_text=yaxis_title, row = 1, col = 2)\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "az8UAayQMKXG"
      },
      "source": [
        "### **Model evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e045dNv5MuMc"
      },
      "outputs": [],
      "source": [
        "_model = create_model(NUM_CLASSES, IMG_SIZE)\n",
        "_model.load_weights(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EJqWza_QlbGa"
      },
      "outputs": [],
      "source": [
        "loss, accuracy = _model.evaluate(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "eLoA6JGNPi4P"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "y_pred = _model.predict(test_dataset)\n",
        "y_pred = np.array([np.argmax(x) for x in y_pred])\n",
        "\n",
        "y_true = [element[1] for element in test_dataset.unbatch().as_numpy_iterator()]\n",
        "y_true = np.array([np.argmax(x) for x in y_true])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "Ot-veofmNhYi"
      },
      "outputs": [],
      "source": [
        "conf_matrix = tf.math.confusion_matrix(y_true, y_pred)\n",
        "conf_matrix = conf_matrix.numpy()\n",
        "class_names = encoder.classes_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ngLOCbMDHH8f"
      },
      "outputs": [],
      "source": [
        "fig = px.imshow(conf_matrix,\n",
        "                labels = dict(x = \"predicted sample\", y=\"true sample\"),\n",
        "                x = class_names,\n",
        "                y = class_names,\n",
        "                text_auto = True,\n",
        "                title = 'Confusion matrix')\n",
        "\n",
        "fig.update_traces(showlegend=False)\n",
        "fig.update_xaxes(side=\"top\")\n",
        "\n",
        "fig.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Implementation",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}